{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de369a20",
   "metadata": {},
   "source": [
    "### What was the highest and lowest pollution measurement ever recorded in zip code 10027?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb8b69c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.56 mcg/m^3 is the highest recorded polution level in 10027\n",
      "7.36 mcg/m^3 is the lowest recorded polution level in 10027\n"
     ]
    }
   ],
   "source": [
    "from project1 import search_by_zipcode\n",
    "\n",
    "zipcode = '10027'\n",
    "measurements = []\n",
    "\n",
    "raw = search_by_zipcode(zipcode)\n",
    "for line in raw:\n",
    "    temp = line.split(', ')\n",
    "    measurements.append(float(temp[-1].split(' ')[0]))\n",
    "print(f'{max(measurements)} mcg/m^3 is the highest recorded polution level in {zipcode}')\n",
    "print(f'{min(measurements)} mcg/m^3 is the lowest recorded polution level in {zipcode}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d35fda",
   "metadata": {},
   "source": [
    "### Which UHF id had the worst pollution in 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7db6e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UHF42 ¦ 306 Chelsea - Clinton ¦ recorded the worst polution reading of 2019 at 11.38 mcg/m^3\n"
     ]
    }
   ],
   "source": [
    "from project1 import search_by_uhf\n",
    "\n",
    "year = '19'\n",
    "uhf_list = ['UHF42', 'UHF34']\n",
    "measurements = []\n",
    "\n",
    "for uhf in uhf_list:    \n",
    "    raw = search_by_uhf(uhf)\n",
    "    for line in raw:\n",
    "        if line.split(', ')[0].split('/')[2] == year:\n",
    "            #print(line.split(', '))\n",
    "            reading = float(line.split(', ')[4].split(' ')[0])\n",
    "            geo_id = line.split(', ')[2]\n",
    "            location = line.split(', ')[3]\n",
    "\n",
    "            measurements.append((uhf, reading, geo_id, location))\n",
    "\n",
    "worst_uhf, worst_polution, worst_geo_id, worst_location = max(measurements, key=lambda L:L[1])\n",
    "\n",
    "print(f'{worst_uhf} ¦ {worst_geo_id} {worst_location} ¦ recorded the worst polution reading of 20{year} at {worst_polution} mcg/m^3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc536cda",
   "metadata": {},
   "source": [
    "### What was the average air pollution in Manhattan in 2008? What was the average pollution in Manhattan in 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c76e9cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average polution, Manhattan 2008:\t15.3 mcg/m^3\n",
      "Average polution, Manhattan 2019:\t9.62 mcg/m^3\n"
     ]
    }
   ],
   "source": [
    "from project1 import search_by_borough\n",
    "\n",
    "def find_average_polution(borough, year):\n",
    "    measurements = []\n",
    "    raw = search_by_borough(borough)\n",
    "    for line in raw:\n",
    "        if line.split(', ')[0].split('/')[2] == year:\n",
    "            reading = float(line.split(', ')[-1].split(' ')[0])\n",
    "            measurements.append(reading)\n",
    "\n",
    "    average = sum(measurements) / len(measurements)\n",
    "    return round(average, 2), borough, year\n",
    "\n",
    "\n",
    "average, borough, year = find_average_polution('Manhattan', '08')\n",
    "print(f'Average polution, {borough} 20{year}:\\t{average} mcg/m^3')\n",
    "\n",
    "average, borough, year = find_average_polution('Manhattan', '19')\n",
    "print(f'Average polution, {borough} 20{year}:\\t{average} mcg/m^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee6c26",
   "metadata": {},
   "source": [
    "### What borough has the greatest internal range of average pollution levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6df0c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan has the greatest range in average polution measurements across its locations\n",
      "StatenIsland has the least range\n"
     ]
    }
   ],
   "source": [
    "from project1 import search_by_borough\n",
    "\n",
    "boroughs = ['Manhattan', 'Bronx', 'Queens', 'Brooklyn', 'StatenIsland']\n",
    "ranges = []\n",
    "\n",
    "for borough in boroughs:\n",
    "    raw = search_by_borough(borough)\n",
    "    dictionary = {}\n",
    "    \n",
    "    for line in raw:\n",
    "        location = line.split(', ')[3]\n",
    "        measurements = line.split(', ')[4].split(' ')[0].strip()\n",
    "        \n",
    "        if location in dictionary:\n",
    "            dictionary[location].append(float(measurements))\n",
    "        else:\n",
    "            dictionary[location] = [float(measurements)]\n",
    "\n",
    "    averages = []\n",
    "    for item in dictionary:\n",
    "        location_average = sum(dictionary[item]) / len(dictionary[item])\n",
    "        averages.append(location_average)\n",
    "    \n",
    "    ranges.append(max(averages) - min(averages))\n",
    "    \n",
    "index = ranges.index(max(ranges))\n",
    "index2 = ranges.index(min(ranges))\n",
    "\n",
    "print(f'{boroughs[index]} has the greatest range in average polution measurements across its locations')\n",
    "print(f'{boroughs[index2]} has the least range')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811c857",
   "metadata": {},
   "source": [
    "### What day had the least average polution across all boroughs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204529f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/1/20\n"
     ]
    }
   ],
   "source": [
    "from project1 import search_by_date\n",
    "import csv\n",
    "\n",
    "valid_dates = set()\n",
    "averages_list = []\n",
    "\n",
    "with open('air_quality.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        valid_dates.add(row[2])\n",
    "\n",
    "    for date in valid_dates:\n",
    "        measurements = [] \n",
    "        raw = search_by_date(date)\n",
    "\n",
    "        for line in raw:\n",
    "            measurements.append(float(line.split(', ')[-1].split(' ')[0]))\n",
    "\n",
    "        averages_list.append(sum(measurements)/ len(measurements))\n",
    "\n",
    "    least_polution = min(averages_list)\n",
    "\n",
    "    index = averages_list.index(least_polution)\n",
    "\n",
    "    print(list(valid_dates)[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
